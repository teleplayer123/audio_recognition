{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\py_repos\\audio_recognition\\test_data\\miaow_16k.wav\n"
     ]
    }
   ],
   "source": [
    "yamnet_model_handle = 'https://tfhub.dev/google/yamnet/1'\n",
    "yamnet_model = hub.load(yamnet_model_handle)\n",
    "# testing_wav_file_name = tf.keras.utils.get_file('miaow_16k.wav',\n",
    "#                                                 'https://storage.googleapis.com/audioset/miaow_16k.wav',\n",
    "#                                                 cache_dir='./',\n",
    "#                                                 cache_subdir='test_data')\n",
    "testing_wav_file_name = os.path.join(os.getcwd(), \"test_data\", \"miaow_16k.wav\")\n",
    "print(testing_wav_file_name)\n",
    "\n",
    "# Utility functions for loading audio files and making sure the sample rate is correct.\n",
    "\n",
    "@tf.function\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\csash\\AppData\\Local\\Temp\\ipykernel_16792\\1242582346.py\", line 21, in load_wav_16k_mono  *\n        wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 462, in resample  **\n        value = tf.vectorized_map(f, input)\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['c:\\\\Users\\\\csash\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['c:\\\\Users\\\\csash\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m testing_wav_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_wav_16k_mono\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtesting_wav_file_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m _ \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mplot(testing_wav_data)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Play the audio file.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filey3kvcibe.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__load_wav_16k_mono\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     13\u001b[0m wav \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msqueeze, (ag__\u001b[38;5;241m.\u001b[39mld(wav),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[0;32m     14\u001b[0m sample_rate \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(sample_rate),), \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mint64), fscope)\n\u001b[1;32m---> 15\u001b[0m wav \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfio\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrate_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate_out\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:462\u001b[0m, in \u001b[0;36mresample\u001b[1;34m(input, rate_in, rate_out, name)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(i):\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_ops\u001b[38;5;241m.\u001b[39mio_audio_resample(\n\u001b[0;32m    459\u001b[0m         i, rate_in\u001b[38;5;241m=\u001b[39mrate_in, rate_out\u001b[38;5;241m=\u001b[39mrate_out, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m    460\u001b[0m     )\n\u001b[1;32m--> 462\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvectorized_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mg1\u001b[39m():\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msqueeze(value, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py:458\u001b[0m, in \u001b[0;36mresample.<locals>.f\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(i):\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcore_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio_audio_resample\u001b[49m(\n\u001b[0;32m    459\u001b[0m         i, rate_in\u001b[38;5;241m=\u001b[39mrate_in, rate_out\u001b[38;5;241m=\u001b[39mrate_out, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m    460\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:88\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, attrb)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attrb):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, attrb)\n",
      "File \u001b[1;32mc:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:84\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod \u001b[38;5;241m=\u001b[39m \u001b[43m_load_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_library\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mod\n",
      "File \u001b[1;32mc:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py:69\u001b[0m, in \u001b[0;36m_load_library\u001b[1;34m(filename, lib)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mNotFoundError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     68\u001b[0m         errs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m---> 69\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munable to open file: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, from paths: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilenames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mcaused by: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     72\u001b[0m )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"C:\\Users\\csash\\AppData\\Local\\Temp\\ipykernel_16792\\1242582346.py\", line 21, in load_wav_16k_mono  *\n        wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 462, in resample  **\n        value = tf.vectorized_map(f, input)\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\audio_ops.py\", line 458, in f\n        return core_ops.io_audio_resample(\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 88, in __getattr__\n        return getattr(self._load(), attrb)\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 84, in _load\n        self._mod = _load_library(self._library)\n    File \"c:\\Users\\csash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_io\\python\\ops\\__init__.py\", line 69, in _load_library\n        raise NotImplementedError(\n\n    NotImplementedError: unable to open file: libtensorflow_io.so, from paths: ['c:\\\\Users\\\\csash\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so']\n    caused by: ['c:\\\\Users\\\\csash\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\site-packages\\\\tensorflow_io\\\\python\\\\ops\\\\libtensorflow_io.so not found']\n"
     ]
    }
   ],
   "source": [
    "testing_wav_data = load_wav_16k_mono(testing_wav_file_name)\n",
    "\n",
    "_ = plt.plot(testing_wav_data)\n",
    "\n",
    "# Play the audio file.\n",
    "display.Audio(testing_wav_data, rate=16000)\n",
    "class_map_path = yamnet_model.class_map_path().numpy().decode('utf-8')\n",
    "class_names =list(pd.read_csv(class_map_path)['display_name'])\n",
    "\n",
    "for name in class_names[:20]:\n",
    "  print(name)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, embeddings, spectrogram = yamnet_model(testing_wav_data)\n",
    "class_scores = tf.reduce_mean(scores, axis=0)\n",
    "top_class = tf.math.argmax(class_scores)\n",
    "inferred_class = class_names[top_class]\n",
    "\n",
    "print(f'The main sound is: {inferred_class}')\n",
    "print(f'The embeddings shape: {embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tf.keras.utils.get_file('esc-50.zip',\n",
    "                        'https://github.com/karoldvl/ESC-50/archive/master.zip',\n",
    "                        cache_dir='./',\n",
    "                        cache_subdir='datasets',\n",
    "                        extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esc50_csv = './datasets/ESC-50-master/meta/esc50.csv'\n",
    "base_data_path = './datasets/ESC-50-master/audio/'\n",
    "\n",
    "pd_data = pd.read_csv(esc50_csv)\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classes = ['dog', 'cat']\n",
    "map_class_to_id = {'dog':0, 'cat':1}\n",
    "\n",
    "filtered_pd = pd_data[pd_data.category.isin(my_classes)]\n",
    "\n",
    "class_id = filtered_pd['category'].apply(lambda name: map_class_to_id[name])\n",
    "filtered_pd = filtered_pd.assign(target=class_id)\n",
    "\n",
    "full_path = filtered_pd['filename'].apply(lambda row: os.path.join(base_data_path, row))\n",
    "filtered_pd = filtered_pd.assign(filename=full_path)\n",
    "\n",
    "filtered_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = filtered_pd['filename']\n",
    "targets = filtered_pd['target']\n",
    "folds = filtered_pd['fold']\n",
    "\n",
    "main_ds = tf.data.Dataset.from_tensor_slices((filenames, targets, folds))\n",
    "main_ds.element_spec\n",
    "\n",
    "def load_wav_for_map(filename, label, fold):\n",
    "  return load_wav_16k_mono(filename), label, fold\n",
    "\n",
    "main_ds = main_ds.map(load_wav_for_map)\n",
    "main_ds.element_spec\n",
    "\n",
    "# applies the embedding extraction model to a wav data\n",
    "def extract_embedding(wav_data, label, fold):\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\n",
    "  scores, embeddings, spectrogram = yamnet_model(wav_data)\n",
    "  num_embeddings = tf.shape(embeddings)[0]\n",
    "  return (embeddings,\n",
    "            tf.repeat(label, num_embeddings),\n",
    "            tf.repeat(fold, num_embeddings))\n",
    "\n",
    "# extract embedding\n",
    "main_ds = main_ds.map(extract_embedding).unbatch()\n",
    "main_ds.element_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_ds = main_ds.cache()\n",
    "train_ds = cached_ds.filter(lambda embedding, label, fold: fold < 4)\n",
    "val_ds = cached_ds.filter(lambda embedding, label, fold: fold == 4)\n",
    "test_ds = cached_ds.filter(lambda embedding, label, fold: fold == 5)\n",
    "\n",
    "# remove the folds column now that it's not needed anymore\n",
    "remove_fold_column = lambda embedding, label, fold: (embedding, label)\n",
    "\n",
    "train_ds = train_ds.map(remove_fold_column)\n",
    "val_ds = val_ds.map(remove_fold_column)\n",
    "test_ds = test_ds.map(remove_fold_column)\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1024), dtype=tf.float32,\n",
    "                          name='input_embedding'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(my_classes))\n",
    "], name='my_model')\n",
    "\n",
    "my_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = my_model.fit(train_ds,\n",
    "                       epochs=20,\n",
    "                       validation_data=val_ds,\n",
    "                       callbacks=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = my_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "scores, embeddings, spectrogram = yamnet_model(testing_wav_data)\n",
    "result = my_model(embeddings).numpy()\n",
    "\n",
    "inferred_class = my_classes[result.mean(axis=0).argmax()]\n",
    "print(f'The main sound is: {inferred_class}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReduceMeanLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self, axis=0, **kwargs):\n",
    "    super(ReduceMeanLayer, self).__init__(**kwargs)\n",
    "    self.axis = axis\n",
    "\n",
    "  def call(self, input):\n",
    "    return tf.math.reduce_mean(input, axis=self.axis)\n",
    "\n",
    "saved_model_path = './dogs_and_cats_yamnet'\n",
    "\n",
    "input_segment = tf.keras.layers.Input(shape=(), dtype=tf.float32, name='audio')\n",
    "embedding_extraction_layer = hub.KerasLayer(yamnet_model_handle,\n",
    "                                            trainable=False, name='yamnet')\n",
    "_, embeddings_output, _ = embedding_extraction_layer(input_segment)\n",
    "serving_outputs = my_model(embeddings_output)\n",
    "serving_outputs = ReduceMeanLayer(axis=0, name='classifier')(serving_outputs)\n",
    "serving_model = tf.keras.Model(input_segment, serving_outputs)\n",
    "serving_model.save(saved_model_path, include_optimizer=False)\n",
    "\n",
    "reloaded_model = tf.saved_model.load(saved_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloaded_results = reloaded_model(testing_wav_data)\n",
    "cat_or_dog = my_classes[tf.math.argmax(reloaded_results)]\n",
    "print(f'The main sound is: {cat_or_dog}')\n",
    "\n",
    "serving_results = reloaded_model.signatures['serving_default'](testing_wav_data)\n",
    "cat_or_dog = my_classes[tf.math.argmax(serving_results['classifier'])]\n",
    "print(f'The main sound is: {cat_or_dog}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = filtered_pd.loc[filtered_pd['fold'] == 5]\n",
    "row = test_pd.sample(1)\n",
    "filename = row['filename'].item()\n",
    "print(filename)\n",
    "waveform = load_wav_16k_mono(filename)\n",
    "print(f'Waveform values: {waveform}')\n",
    "_ = plt.plot(waveform)\n",
    "\n",
    "display.Audio(waveform, rate=16000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model, check the output.\n",
    "scores, embeddings, spectrogram = yamnet_model(waveform)\n",
    "class_scores = tf.reduce_mean(scores, axis=0)\n",
    "top_class = tf.math.argmax(class_scores)\n",
    "inferred_class = class_names[top_class]\n",
    "top_score = class_scores[top_class]\n",
    "print(f'[YAMNet] The main sound is: {inferred_class} ({top_score})')\n",
    "\n",
    "reloaded_results = reloaded_model(waveform)\n",
    "your_top_class = tf.math.argmax(reloaded_results)\n",
    "your_inferred_class = my_classes[your_top_class]\n",
    "class_probabilities = tf.nn.softmax(reloaded_results, axis=-1)\n",
    "your_top_score = class_probabilities[your_top_class]\n",
    "print(f'[Your model] The main sound is: {your_inferred_class} ({your_top_score})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
