{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def load_wav_16k_mono(filename):\n",
    "#     \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "#     file_contents = tf.io.read_file(filename)\n",
    "#     wav, sample_rate = tf.audio.decode_wav(\n",
    "#           file_contents,\n",
    "#           desired_channels=1)\n",
    "#     wav = tf.squeeze(wav, axis=-1)\n",
    "#     sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "#     wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "#     return wav\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportModel(tf.Module):\n",
    "    def __init__(self, model, labels):\n",
    "        self.model = model\n",
    "        self.label_names = labels\n",
    "        # Accept either a string-filename or a batch of waveforms.\n",
    "        # YOu could add additional signatures for a single wave, or a ragged-batch. \n",
    "        self.__call__.get_concrete_function(\n",
    "            x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
    "        self.__call__.get_concrete_function(\n",
    "            x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n",
    "        \n",
    "    def get_spectrogram(self, waveform):\n",
    "        # Convert the waveform to a spectrogram via a STFT (Short-Time Fourier Transform)\n",
    "        spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
    "        # Obtain the magnitude of the STFT.\n",
    "        spectrogram = tf.abs(spectrogram)\n",
    "        # Add a `channels` dimension, so that the spectrogram can be used\n",
    "        # as image-like input data with convolution layers (which expect\n",
    "        # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "        spectrogram = spectrogram[..., tf.newaxis]\n",
    "        return spectrogram\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "    # If they pass a string, load the file and decode it. \n",
    "        if x.dtype == tf.string:\n",
    "            x = tf.io.read_file(x)\n",
    "            x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
    "            x = tf.squeeze(x, axis=-1)\n",
    "            x = x[tf.newaxis, :]\n",
    "        x = self.get_spectrogram(x)  \n",
    "        result = self.model(x, training=False)\n",
    "        class_ids = tf.argmax(result, axis=-1)\n",
    "        class_names = tf.gather(self.label_names, class_ids)\n",
    "        return {'predictions':result,\n",
    "                'class_ids': class_ids,\n",
    "                'class_names': class_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data/mini_speech_commands'\n",
    "\n",
    "data_dir = os.path.join()\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'mini_speech_commands.zip',\n",
    "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import random\n",
    "# import shutil\n",
    "\n",
    "# import librosa\n",
    "# import soundfile as sf\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# import tensorflow as tf\n",
    "\n",
    "\n",
    "# # Create a list of all the background wav files\n",
    "# files = glob.glob(os.path.join('./dataset-speech/_background_noise_', '*.wav'))\n",
    "# files = files + glob.glob(os.path.join('./dataset-background', '*.wav'))\n",
    "\n",
    "# background_dir = './background'\n",
    "# os.makedirs(background_dir, exist_ok=True)\n",
    "\n",
    "# # Loop through all files and split each into several one-second wav files\n",
    "# for file in files:\n",
    "#   filename = os.path.basename(os.path.normpath(file))\n",
    "#   print('Splitting', filename)\n",
    "#   name = os.path.splitext(filename)[0]\n",
    "#   rate = librosa.get_samplerate(file)\n",
    "#   length = round(librosa.get_duration(filename=file))\n",
    "#   for i in range(length - 1):\n",
    "#     start = i * rate\n",
    "#     stop = (i * rate) + rate\n",
    "#     data, _ = sf.read(file, start=start, stop=stop)\n",
    "#     sf.write(os.path.join(background_dir, name + str(i) + '.wav'), data, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 24: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m f0 \u001b[38;5;241m=\u001b[39m file_list[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(f0, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[1;32m---> 11\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mfh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 24: invalid start byte"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "down_dirs = os.path.join(os.getcwd(), \"data\", \"mini_speech_commands\", \"down\")\n",
    "file_list = [os.path.join(down_dirs, fname) for fname in os.listdir(down_dirs)]\n",
    "\n",
    "f0 = file_list[1]\n",
    "\n",
    "with open(f0, \"rb\") as fh:\n",
    "    data = np.array(fh.read())\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav_16k_mono(fname):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    data = tf.io.read_file(fname)\n",
    "    wav, sample_rate = tf.audio.decode_wav(data, desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    rate_out=16000\n",
    "    n_samples = round(len(wav) * rate_out / sample_rate)\n",
    "    wav = sps.resample(wav, n_samples)\n",
    "    return wav"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
