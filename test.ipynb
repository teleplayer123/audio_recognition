{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import tensorflow_io as tfio\n",
    "\n",
    "\n",
    "# @tf.function\n",
    "# def load_wav_16k_mono(filename):\n",
    "#     \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "#     file_contents = tf.io.read_file(filename)\n",
    "#     wav, sample_rate = tf.audio.decode_wav(\n",
    "#           file_contents,\n",
    "#           desired_channels=1)\n",
    "#     wav = tf.squeeze(wav, axis=-1)\n",
    "#     sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "#     wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "#     return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportModel(tf.Module):\n",
    "    def __init__(self, model, labels):\n",
    "        self.model = model\n",
    "        self.label_names = labels\n",
    "        # Accept either a string-filename or a batch of waveforms.\n",
    "        # YOu could add additional signatures for a single wave, or a ragged-batch. \n",
    "        self.__call__.get_concrete_function(\n",
    "            x=tf.TensorSpec(shape=(), dtype=tf.string))\n",
    "        self.__call__.get_concrete_function(\n",
    "            x=tf.TensorSpec(shape=[None, 16000], dtype=tf.float32))\n",
    "        \n",
    "    def get_spectrogram(self, waveform):\n",
    "        # Convert the waveform to a spectrogram via a STFT (Short-Time Fourier Transform)\n",
    "        spectrogram = tf.signal.stft(waveform, frame_length=255, frame_step=128)\n",
    "        # Obtain the magnitude of the STFT.\n",
    "        spectrogram = tf.abs(spectrogram)\n",
    "        # Add a `channels` dimension, so that the spectrogram can be used\n",
    "        # as image-like input data with convolution layers (which expect\n",
    "        # shape (`batch_size`, `height`, `width`, `channels`).\n",
    "        spectrogram = spectrogram[..., tf.newaxis]\n",
    "        return spectrogram\n",
    "\n",
    "    @tf.function\n",
    "    def __call__(self, x):\n",
    "    # If they pass a string, load the file and decode it. \n",
    "        if x.dtype == tf.string:\n",
    "            x = tf.io.read_file(x)\n",
    "            x, _ = tf.audio.decode_wav(x, desired_channels=1, desired_samples=16000,)\n",
    "            x = tf.squeeze(x, axis=-1)\n",
    "            x = x[tf.newaxis, :]\n",
    "        x = self.get_spectrogram(x)  \n",
    "        result = self.model(x, training=False)\n",
    "        class_ids = tf.argmax(result, axis=-1)\n",
    "        class_names = tf.gather(self.label_names, class_ids)\n",
    "        return {'predictions':result,\n",
    "                'class_ids': class_ids,\n",
    "                'class_names': class_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data/mini_speech_commands'\n",
    "\n",
    "data_dir = os.path.join()\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'mini_speech_commands.zip',\n",
    "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
