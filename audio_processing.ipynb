{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.signal as sps\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import m2cgen\n",
    "\n",
    "\n",
    "data_dir = os.path.join(os.getcwd(), \"data\", \"mini_speech_commands\")\n",
    "\n",
    "def downsample_waveform(waveform, num_bins):\n",
    "    waveform = np.array(waveform)\n",
    "    original_length = len(waveform)\n",
    "    points_per_bin = original_length // num_bins\n",
    "    downsampled_waveform = np.zeros(num_bins)\n",
    "    for i in range(num_bins):\n",
    "        start_index = i * points_per_bin\n",
    "        end_index = start_index + points_per_bin\n",
    "        downsampled_waveform[i] = waveform[start_index:end_index].mean()\n",
    "    return downsampled_waveform.tolist()\n",
    "\n",
    "def add_white_noise(audio):\n",
    "    #generate noise and the scalar multiplier\n",
    "    noise = tf.random.uniform(shape=tf.shape(audio), minval=-1, maxval=1)\n",
    "    noise_scalar = tf.random.uniform(shape=[1], minval=0, maxval=0.2)\n",
    "    # add them to the original audio\n",
    "    audio_with_noise = audio + (noise * noise_scalar)\n",
    "    # final clip the values to ensure they are still between -1 and 1\n",
    "    audio_with_noise = tf.clip_by_value(audio_with_noise, clip_value_min=-1, clip_value_max=1)\n",
    "    return audio_with_noise\n",
    "\n",
    "def extract_features(audio_file_path, window_size=1024, overlap=0, num_bins=16):\n",
    "    sample_rate, audio_data = wavfile.read(audio_file_path)\n",
    "    resampled_audio = sps.resample(audio_data, sample_rate)\n",
    "    # Add white noise to the audio\n",
    "    augmented_audio = add_white_noise(resampled_audio)\n",
    "    step_size = window_size - overlap\n",
    "    num_windows = (len(augmented_audio) - window_size) // step_size + 1\n",
    "    fft_results = []\n",
    "    for i in range(num_windows):\n",
    "        start_index = i * step_size\n",
    "        end_index = start_index + window_size\n",
    "        windowed_signal = augmented_audio[start_index:end_index]\n",
    "        \n",
    "        fft_result = np.fft.fft(windowed_signal)\n",
    "        fft_result = fft_result[0:int(fft_result.shape[0] / 2)]\n",
    "        fft_magnitude = np.abs(fft_result)\n",
    "        fft_magnitude[0] = 0\n",
    "        fft_magnitude = downsample_waveform(fft_magnitude, num_bins)\n",
    "        fft_results.extend(fft_magnitude)\n",
    "    return np.array(fft_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir):\n",
    "    waveforms = []\n",
    "    labels = []\n",
    "    for dirname in os.listdir(data_dir):\n",
    "        if dirname in [\"go\", \"stop\"]:\n",
    "            label_dir = os.path.join(data_dir, dirname)\n",
    "            if dirname == \"go\":\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)\n",
    "            wav_files = [os.path.join(label_dir, fname) for fname in os.listdir(label_dir)[:25]]\n",
    "            feature_arr = []\n",
    "            for wav_file in wav_files:\n",
    "                xfeatures = extract_features(wav_file)\n",
    "                feature_arr.append(xfeatures)\n",
    "            waveforms.append(np.array(feature_arr))\n",
    "            del feature_arr\n",
    "        else:\n",
    "            continue\n",
    "    return np.array(waveforms), np.array(labels)\n",
    "\n",
    "\n",
    "audio_data, labels = load_data(data_dir)\n",
    "\n",
    "print(np.shape(audio_data))\n",
    "print(np.shape(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = audio_data[0]\n",
    "plt.figure(figsize=(12, 8))\n",
    "rows = 3\n",
    "cols = 3\n",
    "for i in range(9):\n",
    "  data = a[i]\n",
    "  plt.subplot(rows, cols, i+1)\n",
    "  plt.plot(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "model_params = {\n",
    "    \"activation\": \"relu\",\n",
    "    \"solver\": \"adam\",\n",
    "    \"alpha\": 0.001\n",
    "}\n",
    "\n",
    "x, y = audio_data, labels\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = x.shape[1]*x.shape[2]\n",
    "x_train = np.reshape(x, (2, new_shape))\n",
    "y_train = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel=\"sigmoid\")\n",
    "model.fit(x_train, y_train)\n",
    "score = model.score(x_train, y_train)\n",
    "print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LinearSVC Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = x.shape[1]*x.shape[2]\n",
    "x = np.reshape(x, (3, new_shape))\n",
    "y = np.ravel(y)\n",
    "print(np.shape(x))\n",
    "model = LinearSVC()\n",
    "model.fit(x, y)\n",
    "score = model.score(x_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with SGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = x.shape[1]*x.shape[2]\n",
    "x = np.reshape(x, (3, new_shape))\n",
    "y = np.ravel(y)\n",
    "model = SGDClassifier(random_state=42)\n",
    "x_train = np.reshape(x_train, (2, new_shape))\n",
    "y_train = np.ravel(y_train)\n",
    "model.fit(x, y)\n",
    "x_test = np.reshape(x_test, (1, new_shape))\n",
    "y_test = np.ravel(y_test)\n",
    "score = model.score(x_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile = os.path.join(os.getcwd(), \"models\", \"go_model.pickle\")\n",
    "# with open(outfile, \"wb\") as fh:\n",
    "#     pickle.dump(model, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = os.path.join(os.getcwd(), \"models\", \"go_model.py\")\n",
    "code = m2cgen.export_to_python(model)\n",
    "with open(outfile, \"w\") as fh:\n",
    "    fh.write(code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
